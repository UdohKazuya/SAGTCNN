@inproceedings{GTCNN,
  author = 	 "Kaito Imai and Takamiti Miyata",
  title = 	 "Gated Texture CNN for Efficient and Configurable Image Denoising",
  booktitle =  "European Conference on Computer Vision AIM Workshop",
  year = 	 "2020",
  pages =	 "665-681",
}

@inproceedings{ViT,
  author = 	 "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,and Neil Houlsby",
  title = 	 "An image is worth 16x16 words: Transformers for image recognition at scale",
  booktitle =  "International Conference on Learning Representations",
  year = 	 "2021",
}

@inproceedings{SA,
 Author = "Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin",
 Title = "Attention Is All You Need",
 Year = "2017",
 booktitle = "Advances in Neural Information Processing Systems",
 pages = "5998â€“6008",
}

@inproceedings{Swin,
 Author = {Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
 Title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
 Year = {2021},
 booktitle = {International Conference on Computer Vision},
}

@inproceedings{Restormer,
    title={Restormer: Efficient Transformer for High-Resolution Image Restoration}, 
    author={Syed Waqas Zamir and Aditya Arora and Salman Khan and Munawar Hayat and Fahad Shahbaz Khan and Ming-Hsuan Yang},
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year={2022}
}

@InProceedings{U-net,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}
